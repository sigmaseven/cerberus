package api

import (
	"archive/zip"
	"bytes"
	"fmt"
	"io"
	"mime/multipart"
	"net/http"
	"path/filepath"
	"strings"
	"time"

	"cerberus/core"

	"github.com/google/uuid"
	"gopkg.in/yaml.v3"
)

const (
	// MaxImportFiles limits the number of files in a single import
	MaxImportFiles = 1000
	// MaxImportFileSize limits individual file size (5MB for YAML)
	MaxImportFileSize = 5 * 1024 * 1024
	// MaxImportTotalSize limits total import size (50MB)
	MaxImportTotalSize = 50 * 1024 * 1024
)

// ImportRequest represents an import request
type ImportRequest struct {
	OverwriteExisting bool `form:"overwrite_existing"`
	DryRun            bool `form:"dry_run"`
}

// ImportResponse represents the result of an import operation
type ImportResponse struct {
	Total    int            `json:"total"`
	Imported int            `json:"imported"`
	Updated  int            `json:"updated"`
	Skipped  int            `json:"skipped"`
	Failed   int            `json:"failed"`
	Results  []ImportResult `json:"results"`
}

// ImportResult represents the result for a single file
type ImportResult struct {
	Filename string `json:"filename"`
	Status   string `json:"status"` // imported|updated|skipped|failed
	Message  string `json:"message,omitempty"`
	RuleID   string `json:"rule_id,omitempty"`
}

// handleImportRules imports SIGMA YAML rules from uploaded files
// POST /api/v1/rules/import
//
// Security: File size limits, YAML bomb protection, validation before import
// Production: Supports ZIP archives, individual YAML files, dry-run mode
//
// @Summary		Import rules
// @Description	Import SIGMA YAML rules from files or ZIP archive
// @Tags		rules
// @Accept		multipart/form-data
// @Produce		json
// @Param		files formData file true "YAML files or ZIP archive"
// @Param		overwrite_existing formData bool false "Overwrite existing rules"
// @Param		dry_run formData bool false "Validate without importing"
// @Success		200 {object} ImportResponse
// @Failure		400 {string} string "Invalid request"
// @Failure		500 {string} string "Import failed"
// @Router		/api/v1/rules/import [post]
func (a *API) handleImportRules(w http.ResponseWriter, r *http.Request) {
	// Parse multipart form with size limit
	if err := r.ParseMultipartForm(MaxImportTotalSize); err != nil {
		writeError(w, http.StatusBadRequest, "Failed to parse multipart form", err, a.logger)
		return
	}

	// Parse form parameters
	req := ImportRequest{
		OverwriteExisting: r.FormValue("overwrite_existing") == "true",
		DryRun:            r.FormValue("dry_run") == "true",
	}

	// Get uploaded files
	files := r.MultipartForm.File["files"]
	if len(files) == 0 {
		writeError(w, http.StatusBadRequest, "No files uploaded", nil, a.logger)
		return
	}

	if len(files) > MaxImportFiles {
		writeError(w, http.StatusBadRequest,
			fmt.Sprintf("too many files: %d (max %d)", len(files), MaxImportFiles),
			nil, a.logger)
		return
	}

	// Process files
	response := &ImportResponse{
		Results: []ImportResult{},
	}

	for _, fileHeader := range files {
		a.processImportFile(*fileHeader, req, response)
	}

	// Calculate totals
	response.Total = len(response.Results)
	for _, result := range response.Results {
		switch result.Status {
		case "imported":
			response.Imported++
		case "updated":
			response.Updated++
		case "skipped":
			response.Skipped++
		case "failed":
			response.Failed++
		}
	}

	// CRITICAL-1: Reload detector after successful imports
	if response.Imported > 0 || response.Updated > 0 {
		if err := a.reloadDetectorAfterImport(); err != nil {
			a.logger.Errorw("Failed to reload detector after import", "error", err)
			// Continue - import succeeded but reload failed
		}
	}

	a.logger.Infow("Rule import completed",
		"total", response.Total,
		"imported", response.Imported,
		"updated", response.Updated,
		"skipped", response.Skipped,
		"failed", response.Failed,
		"dry_run", req.DryRun)

	a.respondJSON(w, response, http.StatusOK)
}

// processImportFile processes a single uploaded file (YAML or ZIP)
// CCN: 8 (within limit of 10)
func (a *API) processImportFile(fileHeader multipart.FileHeader, req ImportRequest, response *ImportResponse) {
	// Validate file size
	if fileHeader.Size > MaxImportFileSize {
		response.Results = append(response.Results, ImportResult{
			Filename: fileHeader.Filename,
			Status:   "failed",
			Message:  fmt.Sprintf("file too large: %d bytes (max %d)", fileHeader.Size, MaxImportFileSize),
		})
		return
	}

	// Open file
	file, err := fileHeader.Open()
	if err != nil {
		response.Results = append(response.Results, ImportResult{
			Filename: fileHeader.Filename,
			Status:   "failed",
			Message:  fmt.Sprintf("failed to open file: %v", err),
		})
		return
	}
	defer file.Close()

	// Check file extension
	ext := strings.ToLower(filepath.Ext(fileHeader.Filename))
	switch ext {
	case ".zip":
		a.processZipImport(file, fileHeader.Size, req, response)
	case ".yml", ".yaml":
		a.processSigmaYAMLImport(fileHeader.Filename, file, req, response)
	default:
		response.Results = append(response.Results, ImportResult{
			Filename: fileHeader.Filename,
			Status:   "failed",
			Message:  fmt.Sprintf("unsupported file type: %s (must be .yml, .yaml, or .zip)", ext),
		})
	}
}

// processZipImport extracts and imports rules from ZIP archive
// CCN: 6 (within limit of 10)
func (a *API) processZipImport(file io.Reader, size int64, req ImportRequest, response *ImportResponse) {
	// Read ZIP into memory
	buf := new(bytes.Buffer)
	if _, err := io.Copy(buf, file); err != nil {
		response.Results = append(response.Results, ImportResult{
			Filename: "archive.zip",
			Status:   "failed",
			Message:  fmt.Sprintf("failed to read ZIP: %v", err),
		})
		return
	}

	// Open ZIP reader
	zipReader, err := zip.NewReader(bytes.NewReader(buf.Bytes()), size)
	if err != nil {
		response.Results = append(response.Results, ImportResult{
			Filename: "archive.zip",
			Status:   "failed",
			Message:  fmt.Sprintf("failed to open ZIP: %v", err),
		})
		return
	}

	// Process each file in ZIP
	for _, zipFile := range zipReader.File {
		// Skip directories
		if zipFile.FileInfo().IsDir() {
			continue
		}

		// Only process YAML files
		ext := strings.ToLower(filepath.Ext(zipFile.Name))
		if ext != ".yml" && ext != ".yaml" {
			continue
		}

		// Open file in ZIP
		zf, err := zipFile.Open()
		if err != nil {
			response.Results = append(response.Results, ImportResult{
				Filename: zipFile.Name,
				Status:   "failed",
				Message:  fmt.Sprintf("failed to open file in ZIP: %v", err),
			})
			continue
		}

		a.processSigmaYAMLImport(zipFile.Name, zf, req, response)
		zf.Close()
	}
}

// processSigmaYAMLImport imports a single SIGMA YAML file
// TASK 173 CRITICAL-5: Refactored to â‰¤50 lines by extracting helpers
// CCN: 6 (within limit of 10)
func (a *API) processSigmaYAMLImport(filename string, file io.Reader, req ImportRequest, response *ImportResponse) {
	// CRITICAL-2: Read file with YAML bomb protection
	yamlContent, err := readFileContentSafe(file)
	if err != nil {
		response.Results = append(response.Results, ImportResult{
			Filename: filename, Status: "failed", Message: err.Error(),
		})
		return
	}

	// Parse and build rule
	rule, err := parseSigmaYAMLAndBuildRule(yamlContent)
	if err != nil {
		response.Results = append(response.Results, ImportResult{
			Filename: filename, Status: "failed", Message: err.Error(),
		})
		return
	}

	// TASK 179: Validate rule format (SIGMA YAML enforcement, reject legacy Conditions)
	if err := ValidateRuleForCreation(rule); err != nil {
		response.Results = append(response.Results, ImportResult{
			Filename: filename, Status: "failed",
			Message: fmt.Sprintf("format validation failed: %v", err),
		})
		return
	}

	// Validate rule
	if err := validateRule(rule); err != nil {
		response.Results = append(response.Results, ImportResult{
			Filename: filename, Status: "failed",
			Message: fmt.Sprintf("validation failed: %v", err),
		})
		return
	}

	// Handle dry-run mode
	if req.DryRun {
		response.Results = append(response.Results, ImportResult{
			Filename: filename, Status: "skipped",
			Message: "dry-run mode (validation passed)", RuleID: rule.ID,
		})
		return
	}

	// Import or update rule
	result := a.importOrUpdateRule(rule, req.OverwriteExisting)
	result.Filename = filename
	response.Results = append(response.Results, result)
}

// convertSigmaLevel converts SIGMA severity level to Cerberus severity
func convertSigmaLevel(level string) string {
	switch strings.ToLower(level) {
	case "critical":
		return "Critical"
	case "high":
		return "High"
	case "medium":
		return "Medium"
	case "low", "informational":
		return "Low"
	default:
		return "Medium" // Default to Medium
	}
}

// ExportRequest represents an export request
type ExportRequest struct {
	Format   string   `query:"format"`    // sigma|json
	Category string   `query:"category"`  // detection|correlation|all
	RuleIDs  []string `query:"rule_ids"`  // specific rules or empty for all
}

// handleExportRules exports rules as SIGMA YAML or JSON in ZIP archive
// GET /api/v1/rules/export?format=sigma&category=all
//
// Security: RBAC enforced, file size limits, sanitized filenames
// Production: Streams ZIP to client, supports filtering by category
//
// @Summary		Export rules
// @Description	Export rules as SIGMA YAML or JSON in ZIP archive
// @Tags		rules
// @Produce		application/zip
// @Param		format query string false "Export format (sigma|json)" default(sigma)
// @Param		category query string false "Rule category (detection|correlation|all)" default(all)
// @Param		rule_ids query []string false "Specific rule IDs to export"
// @Success		200 {file} binary "ZIP archive"
// @Failure		400 {string} string "Invalid request"
// @Failure		500 {string} string "Export failed"
// @Router		/api/v1/rules/export [get]
func (a *API) handleExportRules(w http.ResponseWriter, r *http.Request) {
	// Parse query parameters
	req := ExportRequest{
		Format:   r.URL.Query().Get("format"),
		Category: r.URL.Query().Get("category"),
		RuleIDs:  r.URL.Query()["rule_ids"],
	}

	// Default values
	if req.Format == "" {
		req.Format = "sigma"
	}
	if req.Category == "" {
		req.Category = "all"
	}

	// Validate format
	if req.Format != "sigma" && req.Format != "json" {
		writeError(w, http.StatusBadRequest, "format must be sigma or json", nil, a.logger)
		return
	}

	// Validate category
	if req.Category != "detection" && req.Category != "correlation" && req.Category != "all" {
		writeError(w, http.StatusBadRequest, "category must be detection, correlation, or all", nil, a.logger)
		return
	}

	// Get rules to export
	rules, err := a.getRulesToExport(req)
	if err != nil {
		writeError(w, http.StatusInternalServerError, "Failed to get rules for export", err, a.logger)
		return
	}

	if len(rules) == 0 {
		writeError(w, http.StatusBadRequest, "No rules to export", nil, a.logger)
		return
	}

	// Create ZIP archive in memory
	buf := new(bytes.Buffer)
	zipWriter := zip.NewWriter(buf)

	for _, rule := range rules {
		if err := a.addRuleToZip(zipWriter, rule, req.Format); err != nil {
			a.logger.Warnw("Failed to add rule to ZIP", "rule_id", rule.ID, "error", err)
			continue
		}
	}

	if err := zipWriter.Close(); err != nil {
		writeError(w, http.StatusInternalServerError, "Failed to create ZIP archive", err, a.logger)
		return
	}

	// Set response headers
	w.Header().Set("Content-Type", "application/zip")
	w.Header().Set("Content-Disposition", fmt.Sprintf("attachment; filename=rules_export_%d.zip", time.Now().Unix()))
	w.Header().Set("Content-Length", fmt.Sprintf("%d", buf.Len()))

	// Write ZIP to response
	if _, err := w.Write(buf.Bytes()); err != nil {
		a.logger.Errorw("Failed to write ZIP to response", "error", err)
	}

	a.logger.Infow("Rules exported", "count", len(rules), "format", req.Format, "category", req.Category)
}

// getRulesToExport retrieves rules based on export criteria
func (a *API) getRulesToExport(req ExportRequest) ([]core.Rule, error) {
	// If specific IDs provided, fetch those
	if len(req.RuleIDs) > 0 {
		rules := []core.Rule{}
		for _, id := range req.RuleIDs {
			rule, err := a.ruleStorage.GetRule(id)
			if err == nil && rule != nil {
				rules = append(rules, *rule)
			}
		}
		return rules, nil
	}

	// Otherwise, fetch by category
	if req.Category == "detection" || req.Category == "all" {
		return a.ruleStorage.GetAllRules()
	}

	// Correlation rules not supported yet
	return []core.Rule{}, nil
}

// addRuleToZip adds a rule to the ZIP archive
func (a *API) addRuleToZip(zipWriter *zip.Writer, rule core.Rule, format string) error {
	var content []byte
	var filename string
	var err error

	if format == "sigma" {
		// Export as SIGMA YAML
		if rule.SigmaYAML != "" {
			content = []byte(rule.SigmaYAML)
		} else {
			// Rule doesn't have SIGMA YAML, skip
			return fmt.Errorf("rule %s has no SIGMA YAML content", rule.ID)
		}
		filename = fmt.Sprintf("%s.yml", sanitizeFilename(rule.Name))
	} else {
		// Export as JSON
		content, err = yaml.Marshal(rule)
		if err != nil {
			return fmt.Errorf("failed to marshal rule to JSON: %w", err)
		}
		filename = fmt.Sprintf("%s.json", sanitizeFilename(rule.Name))
	}

	// Create file in ZIP
	zipFile, err := zipWriter.Create(filename)
	if err != nil {
		return fmt.Errorf("failed to create ZIP entry: %w", err)
	}

	// Write content
	if _, err := zipFile.Write(content); err != nil {
		return fmt.Errorf("failed to write to ZIP: %w", err)
	}

	return nil
}

// sanitizeFilename removes unsafe characters from filename
// TASK 173 CRITICAL-3: Enhanced path traversal protection
func sanitizeFilename(name string) string {
	// Strip null bytes
	name = strings.ReplaceAll(name, "\x00", "")

	// Unicode normalization to prevent bypass attacks
	// Note: This is a basic implementation; production should use unicode/norm package

	// Replace path separators and unsafe characters with underscores
	replacer := strings.NewReplacer(
		"/", "_",
		"\\", "_",
		":", "_",
		"*", "_",
		"?", "_",
		"\"", "_",
		"<", "_",
		">", "_",
		"|", "_",
		"..", "_", // Prevent directory traversal
	)
	sanitized := replacer.Replace(name)

	// CRITICAL-3: Check for Windows reserved names
	reservedNames := map[string]bool{
		"CON": true, "PRN": true, "AUX": true, "NUL": true,
		"COM1": true, "COM2": true, "COM3": true, "COM4": true,
		"COM5": true, "COM6": true, "COM7": true, "COM8": true, "COM9": true,
		"LPT1": true, "LPT2": true, "LPT3": true, "LPT4": true,
		"LPT5": true, "LPT6": true, "LPT7": true, "LPT8": true, "LPT9": true,
	}
	upperName := strings.ToUpper(sanitized)
	// Check base name without extension
	baseName := strings.Split(upperName, ".")[0]
	if reservedNames[baseName] {
		sanitized = "_" + sanitized // Prefix with underscore to make it safe
	}

	// CRITICAL-3: Enforce length limit (255 bytes for most filesystems)
	if len(sanitized) > 255 {
		sanitized = sanitized[:255]
	}

	// Ensure filename is not empty after sanitization
	if sanitized == "" {
		sanitized = "unnamed_file"
	}

	return sanitized
}

// readFileContentSafe reads file content with YAML bomb protection
// TASK 173 CRITICAL-2: Protects against deeply nested YAML and size bombs
func readFileContentSafe(file io.Reader) (string, error) {
	const maxFileSize = 5 * 1024 * 1024 // 5MB limit

	// Use LimitReader to prevent reading excessive data
	limitedReader := io.LimitReader(file, maxFileSize+1)
	buf := new(bytes.Buffer)

	n, err := io.Copy(buf, limitedReader)
	if err != nil {
		return "", fmt.Errorf("failed to read file: %w", err)
	}

	if n > maxFileSize {
		return "", fmt.Errorf("file too large: exceeds %d bytes", maxFileSize)
	}

	return buf.String(), nil
}

// parseSigmaYAMLAndBuildRule parses SIGMA YAML and builds a core.Rule
// TASK 173 CRITICAL-2 & CRITICAL-5: Extracted from processSigmaYAMLImport with YAML bomb protection
func parseSigmaYAMLAndBuildRule(yamlContent string) (*core.Rule, error) {
	// CRITICAL-2: Parse YAML with depth limit protection
	var sigmaRule map[string]interface{}
	decoder := yaml.NewDecoder(strings.NewReader(yamlContent))
	// yaml.v3 doesn't have explicit depth limit, but we validate structure size below
	if err := decoder.Decode(&sigmaRule); err != nil {
		return nil, fmt.Errorf("invalid YAML: %w", err)
	}

	// CRITICAL-2: Check for suspicious deeply nested structures (YAML bomb detection)
	if depth := calculateMapDepth(sigmaRule); depth > 20 {
		return nil, fmt.Errorf("YAML structure too deeply nested (depth: %d, max: 20)", depth)
	}

	// Extract metadata
	title, _ := sigmaRule["title"].(string)
	description, _ := sigmaRule["description"].(string)
	level, _ := sigmaRule["level"].(string)

	// Create core.Rule from SIGMA YAML
	rule := &core.Rule{
		ID:          uuid.New().String(),
		Type:        "sigma",
		Name:        title,
		Description: description,
		Severity:    convertSigmaLevel(level),
		Version:     1,
		SigmaYAML:   yamlContent,
		Enabled:     true,
		CreatedAt:   time.Now(),
		UpdatedAt:   time.Now(),
	}

	// Extract logsource fields
	if logsource, ok := sigmaRule["logsource"].(map[string]interface{}); ok {
		if category, ok := logsource["category"].(string); ok {
			rule.LogsourceCategory = category
		}
		if product, ok := logsource["product"].(string); ok {
			rule.LogsourceProduct = product
		}
		if service, ok := logsource["service"].(string); ok {
			rule.LogsourceService = service
		}
	}

	// Extract tags
	if tags, ok := sigmaRule["tags"].([]interface{}); ok {
		for _, tag := range tags {
			if tagStr, ok := tag.(string); ok {
				rule.Tags = append(rule.Tags, tagStr)
			}
		}
	}

	return rule, nil
}

// calculateMapDepth calculates the maximum depth of nested maps/slices in a structure
// TASK 173 CRITICAL-2: YAML bomb detection helper
func calculateMapDepth(data interface{}) int {
	switch v := data.(type) {
	case map[string]interface{}:
		maxDepth := 0
		for _, value := range v {
			if depth := calculateMapDepth(value); depth > maxDepth {
				maxDepth = depth
			}
		}
		return maxDepth + 1
	case []interface{}:
		maxDepth := 0
		for _, value := range v {
			if depth := calculateMapDepth(value); depth > maxDepth {
				maxDepth = depth
			}
		}
		return maxDepth + 1
	default:
		return 0
	}
}

// importOrUpdateRule handles rule import/update logic
// TASK 173 CRITICAL-5: Extracted from processSigmaYAMLImport
func (a *API) importOrUpdateRule(rule *core.Rule, overwriteExisting bool) ImportResult {
	// Check if rule exists (by name)
	existingRules, err := a.ruleStorage.GetAllRules()
	if err != nil {
		return ImportResult{
			Status:  "failed",
			Message: fmt.Sprintf("failed to check existing rules: %v", err),
		}
	}

	var existingRule *core.Rule
	for i, r := range existingRules {
		if r.Name == rule.Name {
			existingRule = &existingRules[i]
			break
		}
	}

	// Handle existing rule
	if existingRule != nil {
		if !overwriteExisting {
			return ImportResult{
				Status:  "skipped",
				Message: "rule already exists (overwrite_existing=false)",
				RuleID:  existingRule.ID,
			}
		}

		// Update existing rule
		rule.ID = existingRule.ID // Keep existing ID
		if err := a.ruleStorage.UpdateRule(rule.ID, rule); err != nil {
			return ImportResult{
				Status:  "failed",
				Message: fmt.Sprintf("failed to update rule: %v", err),
			}
		}

		return ImportResult{Status: "updated", RuleID: rule.ID}
	}

	// Create new rule
	if err := a.ruleStorage.CreateRule(rule); err != nil {
		return ImportResult{
			Status:  "failed",
			Message: fmt.Sprintf("failed to create rule: %v", err),
		}
	}

	return ImportResult{Status: "imported", RuleID: rule.ID}
}

// reloadDetectorAfterImport reloads the detector with mutex protection
// TASK 173 CRITICAL-1: Detector reload after import batch completes
// TASK 173 BLOCKER-2: Uses mutex to prevent concurrent reloads
func (a *API) reloadDetectorAfterImport() error {
	if a.detector == nil {
		return nil // No detector configured
	}

	a.detectorReloadMu.Lock()
	defer a.detectorReloadMu.Unlock()

	rules, err := a.ruleStorage.GetAllRules()
	if err != nil {
		return fmt.Errorf("failed to get all rules: %w", err)
	}

	if err := a.detector.ReloadRules(rules); err != nil {
		return fmt.Errorf("failed to reload detector: %w", err)
	}

	return nil
}
